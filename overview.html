<h3 style="text-align: justify;">SemEval 2021 Task 11: <span style="font-variant: small-caps;">NLPContributionGraph</span></h3>
<h4 style="text-align: justify;">Structuring Scholarly NLP Contributions in the Open Research Knowledge Graph</h4>
<p style="text-align: justify;"><span style="font-variant: small-caps;">NLPContributionGraph</span> is introduced as Task 11 at SemEval 2021 for the first time. 
The task is defined on a dataset of NLP scholarly articles with their contributions structured to be integrable within Knowledge Graph infrastructures such as the <a href="https://www.orkg.org/orkg/" target="_blank">Open Research Knowledge Graph</a>.
The structured contribution annotations are provided as: (1) <i>Contribution sentences</i>: a set of sentences about the contribution in the article;
(2) <i>Scientific terms and relations</i>: a set of scientific terms and relational cue phrases extracted from the contribution sentences; 
and (3) <i>Triples</i>: semantic statements that pair scientific terms with a relation, modeled toward subject-predicate-object RDF statements for KG building.					
The <i>Triples</i> are organized under three (mandatory) or more of twelve total information units (viz., <font style="font-variant: small-caps">ResearchProblem</font>, 
<font style="font-variant: small-caps">Approach</font>, <font style="font-variant: small-caps">Model</font>, 
<font style="font-variant: small-caps">Code</font>, <font style="font-variant: small-caps">Dataset</font>, 
<font style="font-variant: small-caps">ExperimentalSetup</font>, <font style="font-variant: small-caps">Hyperparameters</font>, 
<font style="font-variant: small-caps">Baselines</font>, <font style="font-variant: small-caps">Results</font>, 
<font style="font-variant: small-caps">Tasks</font>, <font style="font-variant: small-caps">Experiments</font>, 
and <font style="font-variant: small-caps">AblationAnalysis</font>).
</p>
<h3 style="text-align: justify;">The Shared Task</h3>
<p style="text-align: justify;">As a complete submission for the Shared Task, 
systems will have to extract the following information:</p>
<ol style="text-align: justify;">
<li>contribution sentences;</li>
<li>scientific term and predicate phrases from the sentences; and</li>
<li>(subject,predicate,object) triple statements toward KG building organized under three or more of twelve total information units.</li><br />
</ol>
<p style="text-align: justify;">For example, given the article:</p>
<blockquote>
<p class="wi-article-title article-title-main"><a href="https://doi.org/10.1093/bioinformatics/btz682" target="_blank">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</a></p>
</blockquote>
<p style="text-align: justify;">Systems should identify:</p>
<ul style="text-align: justify;">
<li>Sentence:
<ul>
<li>We used the BERT<sub><span class="monospace">BASE</span></sub> model pre-trained on English Wikipedia and BooksCorpus for 1M steps.</li>
</ul>
</li>
<li>Scientific Term and Predicate Phrases:
<ul>
<li>used</li>
<li>BERT<sub><span class="monospace">BASE</span></sub> model</li>
<li>pre-trained on</li>
<li>English Wikipedia</li>
<li>BooksCorpus</li>
<li>for</li>
<li>1M steps</li>
</ul>
</li>
<li>Triples:
<ul>
<li>(<span style="font-variant: small-caps;">Contribution</span>, has, <span style="font-variant: small-caps;">ExperimentalSetup</span>)</li>
<li>(<span style="font-variant: small-caps;">ExperimentalSetup</span>, used, BERT<sub><span class="monospace">BASE</span></sub> model)</li>
<li>(BERT<sub><span class="monospace">BASE</span></sub> model, pre-trained on, English Wikipedia)</li>
<li>(BERT<sub><span class="monospace">BASE</span></sub> model, pre-trained on, BooksCorpus)</li>
<li>(BERT<sub><span class="monospace">BASE</span></sub> model, for, 1M steps)</li>
</ul>
</li>
</ul>
<p style="text-align: justify;">Note that the above example is only for one contribution-related sentence from the article. 
The participating systems should identify all the contribution-related sentences and accordingly perform the subsequent Phrases and Triples extraction tasks given the sentences,
where the Triples extraction task entails categorizing a triples sequence under one of the twelve information units. In the example above,
the set of triples pertain to the <span style="font-variant: small-caps;">ExperimentalSetup</span> information unit and, for the evaluation submission, 
will need to be saved in a file named after the information unit.
More the details on the task submission format can be in the <span style="color:#5dade2">Evaluation</span> page.</p>